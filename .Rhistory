return(means_sds)
}
# Function to set variable types based on dlookr diagnostics
set_variable_types <- function(merged, types) {
for (i in 1:nrow(types)) {
var <- types$variables[i]
type <- types$types[i]
if (type == "numeric") {
merged[[var]] <- as.numeric(merged[[var]])
} else if (type == "factor") {
merged[[var]] <- as.factor(merged[[var]])
} else if (type == "integer") {
merged[[var]] <- as.integer(merged[[var]])
} else if (type == "character") {
merged[[var]] <- as.character(merged[[var]])
}
# Add other types as necessary
}
return(merged)
}
# Function to convert character variables to factors
convert_char_to_factor <- function(merged) {
merged <- merged %>%
mutate(across(where(is.character), as.factor))
return(merged)
}
# Function to calculate the mode for factor variables
calculate_modes <- function(merged) {
modes <- sapply(merged, function(x) if(is.factor(x)) {
mode_value <- names(sort(table(x), decreasing = TRUE)[1])
mode_count <- max(table(x))
mode_percentage <- (mode_count / length(x)) * 100
paste0(mode_value, " (", round(mode_percentage, 2), "%)")
} else NA)
return(modes)
}
# Function to calculate date statistics for POSIXct columns
calculate_date_statistics <- function(merged) {
date_stats <- sapply(merged, function(x) if(inherits(x, "POSIXct")) {
min_date <- format(min(x, na.rm = TRUE), "%Y-%m-%d")
max_date <- format(max(x, na.rm = TRUE), "%Y-%m-%d")
num_unique_dates <- length(unique(x))
median_date <- format(median(x, na.rm = TRUE), "%Y-%m-%d")
paste0(min_date, " to ", max_date)
} else NA)
return(date_stats)
}
# Function to count the number of levels for factor variables
count_levels <- function(merged) {
num_levels <- sapply(merged, function(x) if(is.factor(x)) length(levels(x)) else NA)
return(num_levels)
}
# Function to mask sensitive data, only for existing columns
mask_sensitive_data <- function(merged, sensitive_vars) {
existing_sensitive_vars <- intersect(names(merged), sensitive_vars)
if(length(existing_sensitive_vars) > 0) {
merged <- merged %>%
mutate(across(all_of(existing_sensitive_vars), ~ "Masked"))
}
return(merged)
}
# List of sensitive variables to exclude
#sensitive_vars <- c("youth_num_in_cohort", "mhs2_juvenile_id", "dob", "assessment_po")
# "unique_id"
# Apply the cleaning function to the dataset
merged_clean <- clean_variable_names(merged)
# Convert character variables to factors
#merged_clean <- convert_char_to_factor(merged_clean)
# Determine variable types using dlookr
variable_types <- diagnose(merged_clean) %>%
select(variables, types)
# Set variable types based on dlookr diagnostics
merged_clean <- set_variable_types(merged_clean, variable_types)
# Mask sensitive data
merged_clean <- mask_sensitive_data(merged_clean, sensitive_vars)
# Create a mapping table of original and cleaned names, excluding sensitive variables
mapping_table <- tibble(
original_name = names(merged),
cleaned_name = names(merged_clean)
) %>%
filter(!cleaned_name %in% sensitive_vars)
# Calculate means and standard deviations for numeric columns
means_sds <- calculate_means_sds(merged_clean)
# Calculate modes for factor columns
modes <- calculate_modes(merged_clean)
# Calculate date statistics for POSIXct columns
date_statistics <- calculate_date_statistics(merged_clean)
# Count the number of levels for factor variables
num_levels <- count_levels(merged_clean)
# Combine means, modes, date statistics, and sensitive summaries into separate columns
mapping_table <- mapping_table %>%
mutate(mean_sd = means_sds[!names(means_sds) %in% sensitive_vars],
mode = modes[!names(modes) %in% sensitive_vars],
date_range = date_statistics[!names(date_statistics) %in% sensitive_vars],
num_levels = num_levels[!names(num_levels) %in% sensitive_vars]) %>%
left_join(variable_types, by = c("cleaned_name" = "variables"))
# Ensure all numeric values in the table are rounded to two decimal places
mapping_table <- mapping_table %>%
mutate(across(where(is.numeric), ~ round(., 2)))
# Reorder the columns so that summary_statistic is before original_name
mapping_table <- mapping_table %>%
select(cleaned_name, mean_sd, mode, date_range, num_levels, original_name, types)
View(merged_clean)
str(merged_clean$youth_num_in_cohort)
str(merged$youth_num_in_cohort)
View(merged)
str(merged$YOUTH_NUM_IN_COHORT)
convert_char_to_factor <- function(merged) {
merged <- merged %>%
mutate(across(where(is.character), as.factor))
return(merged)
}
str(merged$YOUTH_NUM_IN_COHORT)
str(merged$youth_num_in_cohort)
str(merged$YOUTH_NUM_IN_COHORT)
merged$YOUTH_NUM_IN_COHORT <- as.factor(merged$YOUTH_NUM_IN_COHORT)
str(merged$YOUTH_NUM_IN_COHORT)
str(merged$UNIQUE_ID)
merged$UNIQUE_ID <- as.factor(merged$UNIQUE_ID)
str(merged$UNIQUE_ID)
# Extract the first 5 characters to identify the cohort
cohort_identifiers <- substr(merged$YOUTH_NUM_IN_COHORT, 1, 5)
# Convert the cohort identifiers to a factor
cohort_identifiers <- as.factor(cohort_identifiers)
# Determine the number of unique cohorts
num_cohorts <- nlevels(cohort_identifiers)
# Print the number of cohorts
print(num_cohorts)
# Extract the first 5 characters to identify the cohort
cohort_identifiers <- substr(merged$YOUTH_NUM_IN_COHORT, 1, 5)
# Count the number of participants in each cohort
participants_per_cohort <- table(cohort_identifiers)
# Convert the result to a data frame for better readability (optional)
participants_per_cohort_df <- as.data.frame(participants_per_cohort)
colnames(participants_per_cohort_df) <- c("Cohort", "Number_of_Participants")
# Print the data frame
print(participants_per_cohort_df)
# Extract the first 5 characters to identify the cohort
cohort_identifiers <- substr(merged$YOUTH_NUM_IN_COHORT, 1, 5)
str(cohort_identifiers)
str(merged$YOUTH_NUM_IN_COHORT)
View(participants_per_cohort_df)
# Print the number of cohorts
print(num_cohorts)
# Extract the first 5 characters to identify the cohort and create a new variable
merged$Cohort <- substr(merged$YOUTH_NUM_IN_COHORT, 1, 5)
# Convert the new variable to an unordered factor
merged$Cohort <- as.factor(merged$Cohort)
# Verify the new variable
str(merged$Cohort)
str(merged$TOTALSCORE)
str(merged$Total_Risk_Desc)
# Convert the new variable to an unordered factor
merged$Total_Risk_Desc <- as.factor(merged$Total_Risk_Desc)
str(merged$Total_Risk_Desc)
# Convert the new variable to an unordered factor
merged$Total_Risk_Desc <- as.factor(merged$Total_Risk_Desc)
# Step 1: Create a contingency table
contingency_table <- table(merged$Cohort, merged$Total_Risk_Desc)
print(contingency_table)
# Step 2: Visualize the association with a bar plot
library(ggplot2)
ggplot(merged, aes(x = Cohort, fill = Total_Risk_Desc)) +
geom_bar(position = "dodge") +
labs(title = "Bar Plot of Cohort by Total Risk Description", x = "Cohort", y = "Count") +
theme_minimal()
# Step 2: Visualize the association with a mosaic plot
library(vcd)
install.packages('vcd')
# Convert the new variable to an unordered factor
merged$Total_Risk_Desc <- as.factor(merged$Total_Risk_Desc)
# Step 1: Create a contingency table
contingency_table <- table(merged$Cohort, merged$Total_Risk_Desc)
print(contingency_table)
# Step 2: Visualize the association with a bar plot
library(ggplot2)
ggplot(merged, aes(x = Cohort, fill = Total_Risk_Desc)) +
geom_bar(position = "dodge") +
labs(title = "Bar Plot of Cohort by Total Risk Description", x = "Cohort", y = "Count") +
theme_minimal()
# Step 2: Visualize the association with a mosaic plot
library(vcd)
mosaic(~ Cohort + Total_Risk_Desc, data = merged, shade = TRUE, legend = TRUE)
# Step 3: Conduct a chi-square test
chi_square_test <- chisq.test(contingency_table)
print(chi_square_test)
# Step 1: Create a contingency table
contingency_table <- table(merged$Cohort, merged$Total_Risk_Desc)
# Step 2: Convert the contingency table to a data frame
contingency_df <- as.data.frame.matrix(contingency_table)
# Step 3: Add a new column with the total count of individuals in each cohort
contingency_df$Total <- rowSums(contingency_df)
# Print the data frame
print(contingency_df)
# Install the packages if not already installed
install.packages("knitr")
install.packages("kableExtra")
# Load the packages
library(knitr)
library(kableExtra)
# Step 1: Create a contingency table
contingency_table <- table(merged$Cohort, merged$Total_Risk_Desc)
# Step 2: Convert the contingency table to a data frame
contingency_df <- as.data.frame.matrix(contingency_table)
# Step 3: Add a new column with the total count of individuals in each cohort
contingency_df$Count <- rowSums(contingency_df)
# Step 4: Create and format the table using kable and kableExtra
formatted_table <- contingency_df %>%
rownames_to_column(var = "Cohort") %>%
kable("html", col.names = c("Cohort", "High", "Low", "Moderate", "Very High", "Count")) %>%
kable_styling(full_width = F, position = "center", bootstrap_options = c("striped", "hover", "condensed", "responsive"))
# Save the formatted table as HTML
#save_kable(formatted_table, file = "cohort_risk_table.html")
install.packages("kableExtra")
install.packages("knitr")
# Load the packages
library(knitr)
library(kableExtra)
# Step 1: Create a contingency table
contingency_table <- table(merged$Cohort, merged$Total_Risk_Desc)
# Step 2: Convert the contingency table to a data frame
contingency_df <- as.data.frame.matrix(contingency_table)
# Step 3: Add a new column with the total count of individuals in each cohort
contingency_df$Count <- rowSums(contingency_df)
# Step 4: Create and format the table using kable and kableExtra
formatted_table <- contingency_df %>%
rownames_to_column(var = "Cohort") %>%
kable("html", col.names = c("Cohort", "High", "Low", "Moderate", "Very High", "Count")) %>%
kable_styling(full_width = F, position = "center", bootstrap_options = c("striped", "hover", "condensed", "responsive"))
formatted_table
# Load the packages
library(knitr)
library(kableExtra)
# Step 1: Create a contingency table
contingency_table <- table(merged$Cohort, merged$Total_Risk_Desc)
# Step 2: Convert the contingency table to a data frame
contingency_df <- as.data.frame.matrix(contingency_table)
# Step 3: Add a new column with the total count of individuals in each cohort
contingency_df$Total <- rowSums(contingency_df)
# Step 4: Rename the 'Total' column to 'Count'
contingency_df <- contingency_df %>%
rownames_to_column(var = "Cohort") %>%
rename(Count = Total)
# Step 5: Reorder columns so 'Count' is the second column
contingency_df <- contingency_df %>%
select(Cohort, Count, everything())
# Step 6: Sort the data frame in descending order based on 'Count'
contingency_df <- contingency_df %>%
arrange(desc(Count))
# Step 7: Create and format the table using kable and kableExtra
formatted_table <- contingency_df %>%
kable("html", col.names = c("Cohort", "Count", "High", "Low", "Moderate", "Very High")) %>%
kable_styling(full_width = F, position = "center", bootstrap_options = c("striped", "hover", "condensed", "responsive"))
# Save the formatted table as HTML
#save_kable(formatted_table, file = "cohort_risk_table.html")
formatted_table
# Load the packages
library(knitr)
library(kableExtra)
# Step 1: Create a contingency table
contingency_table <- table(merged$Cohort, merged$Total_Risk_Desc)
# Step 2: Convert the contingency table to a data frame
contingency_df <- as.data.frame.matrix(contingency_table)
# Step 3: Add a new column with the total count of individuals in each cohort
contingency_df$Total <- rowSums(contingency_df)
# Step 4: Rename the 'Total' column to 'Count'
contingency_df <- contingency_df %>%
rownames_to_column(var = "Cohort") %>%
rename(Count = Total)
# Step 5: Reorder columns so 'Count' is the second column
contingency_df <- contingency_df %>%
select(Cohort, Count, everything())
# Step 6: Calculate proportions for each risk category
contingency_df <- contingency_df %>%
mutate(across(c(High, Low, Moderate, `Very High`), ~ . / Count, .names = "prop_{col}"))
# Step 7: Sort the data frame in descending order based on 'Count'
contingency_df <- contingency_df %>%
arrange(desc(Count))
# Step 8: Create and format the table using kable and kableExtra
formatted_table <- contingency_df %>%
kable("html", col.names = c("Cohort", "Count", "High", "Prop High", "Low", "Prop Low", "Moderate", "Prop Moderate", "Very High", "Prop Very High")) %>%
kable_styling(full_width = F, position = "center", bootstrap_options = c("striped", "hover", "condensed", "responsive"))
# Save the formatted table as HTML
#save_kable(formatted_table, file = "cohort_risk_table.html")
formatted_table
# Load the packages
library(knitr)
library(kableExtra)
# Step 1: Create a contingency table
contingency_table <- table(merged$Cohort, merged$Total_Risk_Desc)
# Step 2: Convert the contingency table to a data frame
contingency_df <- as.data.frame.matrix(contingency_table)
# Step 3: Add a new column with the total count of individuals in each cohort
contingency_df$Total <- rowSums(contingency_df)
# Step 4: Rename the 'Total' column to 'Count'
contingency_df <- contingency_df %>%
rownames_to_column(var = "Cohort") %>%
rename(Count = Total)
# Step 5: Calculate proportions for each risk category and format them as percentages
contingency_df <- contingency_df %>%
mutate(across(c(High, Low, Moderate, `Very High`), ~ sprintf("%d (%d%%)", ., round(./Count * 100))))
# Step 6: Reorder columns so 'Count' is the second column
contingency_df <- contingency_df %>%
select(Cohort, Count, everything())
# Step 7: Sort the data frame in descending order based on 'Count'
contingency_df <- contingency_df %>%
arrange(desc(Count))
# Step 8: Create and format the table using kable and kableExtra
formatted_table <- contingency_df %>%
kable("html", col.names = c("Cohort", "Count", "High", "Low", "Moderate", "Very High")) %>%
kable_styling(full_width = F, position = "center", bootstrap_options = c("striped", "hover", "condensed", "responsive"))
# Save the formatted table as HTML
#save_kable(formatted_table, file = "cohort_risk_table.html")
formatted_table
# Step 2: Convert the contingency table to a data frame
contingency_df <- as.data.frame.matrix(contingency_table)
formatted_table
# Load the packages
library(knitr)
library(kableExtra)
# Step 1: Create a contingency table
contingency_table <- table(merged$Cohort, merged$Total_Risk_Desc)
# Step 2: Convert the contingency table to a data frame
contingency_df <- as.data.frame.matrix(contingency_table)
# Step 3: Add a new column with the total count of individuals in each cohort
contingency_df$Total <- rowSums(contingency_df)
# Step 4: Rename the 'Total' column to 'Count'
contingency_df <- contingency_df %>%
rownames_to_column(var = "Cohort") %>%
rename(Count = Total)
# Step 5: Calculate proportions for each risk category and format them as percentages
contingency_df <- contingency_df %>%
mutate(across(c(High, Low, Moderate, `Very High`), ~ sprintf("%d (%d%%)", ., round(./Count * 100))))
# Step 6: Calculate mean and standard deviation for the totalscore variable for each cohort
mean_sd <- merged %>%
group_by(Cohort) %>%
summarize(mean_sd = sprintf("%.2f (%.2f)", mean(totalscore, na.rm = TRUE), sd(totalscore, na.rm = TRUE)))
# Load the packages
library(knitr)
library(kableExtra)
# Step 1: Create a contingency table
contingency_table <- table(merged$Cohort, merged$Total_Risk_Desc)
# Step 2: Convert the contingency table to a data frame
contingency_df <- as.data.frame.matrix(contingency_table)
# Step 3: Add a new column with the total count of individuals in each cohort
contingency_df$Total <- rowSums(contingency_df)
# Step 4: Rename the 'Total' column to 'Count'
contingency_df <- contingency_df %>%
rownames_to_column(var = "Cohort") %>%
rename(Count = Total)
# Step 5: Calculate proportions for each risk category and format them as percentages
contingency_df <- contingency_df %>%
mutate(across(c(High, Low, Moderate, `Very High`), ~ sprintf("%d (%d%%)", ., round(./Count * 100))))
# Step 6: Calculate mean and standard deviation for the totalscore variable for each cohort
mean_sd <- merged %>%
group_by(Cohort) %>%
summarize(mean_sd = sprintf("%.2f (%.2f)", mean(TOTALSCORE, na.rm = TRUE), sd(totalscore, na.rm = TRUE)))
str(merged$TOTALSCORE)
# Load the packages
library(knitr)
library(kableExtra)
# Step 1: Create a contingency table
contingency_table <- table(merged$Cohort, merged$Total_Risk_Desc)
# Step 2: Convert the contingency table to a data frame
contingency_df <- as.data.frame.matrix(contingency_table)
# Step 3: Add a new column with the total count of individuals in each cohort
contingency_df$Total <- rowSums(contingency_df)
# Step 4: Rename the 'Total' column to 'Count'
contingency_df <- contingency_df %>%
rownames_to_column(var = "Cohort") %>%
rename(Count = Total)
# Step 5: Calculate proportions for each risk category and format them as percentages
contingency_df <- contingency_df %>%
mutate(across(c(High, Low, Moderate, `Very High`), ~ sprintf("%d (%d%%)", ., round(./Count * 100))))
# Step 6: Calculate mean and standard deviation for the totalscore variable for each cohort
mean_sd <- merged %>%
group_by(Cohort) %>%
summarize(mean_sd = sprintf("%.2f (%.2f)", mean(TOTALSCORE, na.rm = TRUE), sd(TOTALSCORE, na.rm = TRUE)))
# Step 7: Merge the mean(sd) statistics with the contingency table
contingency_df <- left_join(contingency_df, mean_sd, by = "Cohort")
# Step 8: Reorder columns so 'Count' is the second column
contingency_df <- contingency_df %>%
select(Cohort, Count, mean_sd, everything())
# Step 9: Sort the data frame in descending order based on 'Count'
contingency_df <- contingency_df %>%
arrange(desc(Count))
# Step 10: Create and format the table using kable and kableExtra
formatted_table <- contingency_df %>%
kable("html", col.names = c("Cohort", "Count", "Mean(SD)", "High", "Low", "Moderate", "Very High")) %>%
kable_styling(full_width = F, position = "center", bootstrap_options = c("striped", "hover", "condensed", "responsive"))
# Save the formatted table as HTML
#save_kable(formatted_table, file = "cohort_risk_table.html")
formatted_table
# Calculate the total count for each cohort
count_df <- merged %>%
group_by(Cohort) %>%
summarize(Count = n())
# Calculate the mean totalscore for each cohort
mean_totalscore_df <- merged %>%
group_by(Cohort) %>%
summarize(Mean_TOTALSCORE = mean(totalscore, na.rm = TRUE))
# Calculate the total count for each cohort
count_df <- merged %>%
group_by(Cohort) %>%
summarize(Count = n())
# Calculate the mean totalscore for each cohort
mean_totalscore_df <- merged %>%
group_by(Cohort) %>%
summarize(Mean_TOTALSCORE = mean(Mean_TOTALSCORE, na.rm = TRUE))
# Calculate the total count for each cohort
count_df <- merged %>%
group_by(Cohort) %>%
summarize(Count = n())
# Calculate the mean totalscore for each cohort
mean_totalscore_df <- merged %>%
group_by(Cohort) %>%
summarize(TOTALSCORE = mean(TOTALSCORE, na.rm = TRUE))
# Merge the count and mean totalscore data frames
merged_df <- left_join(count_df, mean_totalscore_df, by = "Cohort")
# Calculate the correlation between Count and Mean_TOTALSCORE
correlation <- cor(merged_df$Count, merged_df$Mean_TOTALSCORE, use = "complete.obs")
# Merge the count and mean totalscore data frames
merged_df <- left_join(count_df, mean_TOTALSCORE_df, by = "Cohort")
# Calculate the mean totalscore for each cohort
mean_totalscore_df <- merged %>%
group_by(Cohort) %>%
summarize(TOTALSCORE = mean(TOTALSCORE, na.rm = TRUE))
# Merge the count and mean totalscore data frames
merged_df <- left_join(count_df, mean_totalscore_df, by = "Cohort")
# Calculate the correlation between Count and Mean_TOTALSCORE
correlation <- cor(merged_df$Count, merged_df$Mean_TOTALSCORE, use = "complete.obs")
merged_df
# Calculate the correlation between Count and Mean_TOTALSCORE
correlation <- cor(merged_df$Count, merged_df$TOTALSCORE, use = "complete.obs")
# Print the correlation
print(correlation)
summary(correlation)
# Calculate the total count for each cohort
count_df <- merged %>%
group_by(Cohort) %>%
summarize(Count = n())
# Calculate the mean totalscore for each cohort
mean_totalscore_df <- merged %>%
group_by(Cohort) %>%
summarize(TOTALSCORE = mean(TOTALSCORE, na.rm = TRUE))
# Merge the count and mean totalscore data frames
merged_df <- left_join(count_df, mean_totalscore_df, by = "Cohort")
# Perform a correlation test between Count and Mean_TOTALSCORE
correlation_test <- cor.test(merged_df$Count, merged_df$TOTALSCORE, use = "complete.obs")
# Extract the sample size, correlation coefficient, and p-value
sample_size <- length(na.omit(merged_df$Count))
correlation_coefficient <- correlation_test$estimate
p_value <- correlation_test$p.value
# Print the results
cat("Sample Size:", sample_size, "\n")
cat("Correlation Coefficient:", correlation_coefficient, "\n")
cat("P-value:", p_value, "\n")
# Load the packages
library(knitr)
library(kableExtra)
# Step 1: Create a contingency table
contingency_table <- table(merged$Cohort, merged$Total_Risk_Desc)
# Step 2: Convert the contingency table to a data frame
contingency_df <- as.data.frame.matrix(contingency_table)
# Step 3: Add a new column with the total count of individuals in each cohort
contingency_df$Total <- rowSums(contingency_df)
# Step 4: Rename the 'Total' column to 'Count'
contingency_df <- contingency_df %>%
rownames_to_column(var = "Cohort") %>%
rename(Count = Total)
# Step 5: Calculate proportions for each risk category and format them as percentages
contingency_df <- contingency_df %>%
mutate(across(c(High, Low, Moderate, `Very High`), ~ sprintf("%d (%d%%)", ., round(./Count * 100))))
# Step 6: Calculate mean and standard deviation for the totalscore variable for each cohort
mean_sd <- merged %>%
group_by(Cohort) %>%
summarize(mean_sd = sprintf("%.2f (%.2f)", mean(TOTALSCORE, na.rm = TRUE), sd(TOTALSCORE, na.rm = TRUE)))
# Step 7: Merge the mean(sd) statistics with the contingency table
contingency_df <- left_join(contingency_df, mean_sd, by = "Cohort")
# Step 8: Reorder columns so 'Count' is the second column
contingency_df <- contingency_df %>%
select(Cohort, Count, mean_sd, everything())
# Step 9: Sort the data frame in descending order based on 'Count'
contingency_df <- contingency_df %>%
arrange(desc(Count))
# Step 10: Create and format the table using kable and kableExtra
formatted_table <- contingency_df %>%
kable("html", col.names = c("Cohort", "Count", "Mean(SD)", "High", "Low", "Moderate", "Very High")) %>%
kable_styling(full_width = F, position = "center", bootstrap_options = c("striped", "hover", "condensed", "responsive"))
# Save the formatted table as HTML
#save_kable(formatted_table, file = "cohort_risk_table.html")
formatted_table
# Calculate the total count for each cohort
count_df <- merged %>%
group_by(Cohort) %>%
summarize(Count = n())
# Calculate the mean totalscore for each cohort
mean_totalscore_df <- merged %>%
group_by(Cohort) %>%
summarize(TOTALSCORE = mean(TOTALSCORE, na.rm = TRUE))
# Merge the count and mean totalscore data frames
merged_df <- left_join(count_df, mean_totalscore_df, by = "Cohort")
# Perform a correlation test between Count and Mean_TOTALSCORE
correlation_test <- cor.test(merged_df$Count, merged_df$TOTALSCORE, use = "complete.obs")
# Extract the sample size, correlation coefficient, and p-value
sample_size <- length(na.omit(merged_df$Count))
correlation_coefficient <- correlation_test$estimate
p_value <- correlation_test$p.value
# Print the results
cat("Sample Size:", sample_size, "\n")
cat("Correlation Coefficient:", correlation_coefficient, "\n")
cat("P-value:", p_value, "\n")
