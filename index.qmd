---
title: "SPEP Revalidation"
#author: "Name Here"
---

## Preliminary Setup

::: panel-tabset

### Config Options

::: blue
> **This code configures knitr code chunk options**

```{r config}
#| echo: true
#| messages: FALSE
#| warning: FALSE
#| output: FALSE

knitr::opts_chunk$set(
    echo = T, message = F, warning = F, error = F,
    comment = NA, cache = T, code_folding = T,
    R.options = list(width = 220, digits = 3),
    fig.align = "center",
    out.width = "75%", fig.asp = .75
)
```
:::

### Install Packages {.tabset .tabset-fade .tabset-pills}

::: blue
> **This code loads the r packages necessary for this example**

```{r}
#| echo: true
#| warning: false
#| output: false

library(tidyverse)
library(readxl)
library(gtsummary)
library(DT)
library(patchwork)
library(dlookr)
library(kableExtra)
library(knitr)
library(openxlsx)
library(psych)
library(janitor)

```

:::

### Load Data
> **This code loads the dataframe**

```{r}
#| echo: true
#| warning: false
#| output: false

# Read the data from an Excel file
merged <- read_excel("/Users/shawes/PA_JCMS/data/Merged_Files_NoRecid.xlsx")
```

### Prep data {.tabset .tabset-fade .tabset-pills}

::: blue
> **This code prepares the dataset for analysis**

```{r}
#| echo: true
#| warning: false
#| output: false

## % Missingness by Variable

# Calculate the percentage of missing data for each column
missing_data_percentages <- merged %>%
  summarise(across(everything(), ~ mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "missing_percentage")

# Filter out columns with >= 90% missing data
columns_to_keep <- missing_data_percentages %>%
  filter(missing_percentage < 90) %>%
  pull(variable)

# Select the columns to keep
merged <- merged %>%
  select(all_of(columns_to_keep))
```

```{r}
#| echo: true
#| warning: false

## Prep data

# List of sensitive variables to exclude
sensitive_vars <- c("mhs2_juvenile_id", "dob", "assessment_po")
## "unique_id", "youth_num_in_cohort"

# Function to clean variable names
clean_variable_names <- function(merged) {
  cleaned_names <- merged %>%
    names() %>%
    str_replace_all("[^[:alnum:]_]", "_") %>%
    str_replace_all("__+", "_") %>%
    str_trim() %>%
    tolower()
  
  # Ensure unique names
  cleaned_names <- make.unique(cleaned_names)
  
  names(merged) <- cleaned_names
  return(merged)
}

# Function to calculate means and standard deviations for numeric columns
calculate_means_sds <- function(merged) {
  means_sds <- sapply(merged, function(x) if(is.numeric(x)) {
    mean_value <- round(mean(x, na.rm = TRUE), 2)
    sd_value <- round(sd(x, na.rm = TRUE), 2)
    paste0(mean_value, " (", sd_value, ")")
  } else NA)
  return(means_sds)
}

# Function to set variable types based on dlookr diagnostics
set_variable_types <- function(merged, types) {
  for (i in 1:nrow(types)) {
    var <- types$variables[i]
    type <- types$types[i]
    if (type == "numeric") {
      merged[[var]] <- as.numeric(merged[[var]])
    } else if (type == "factor") {
      merged[[var]] <- as.factor(merged[[var]])
    } else if (type == "integer") {
      merged[[var]] <- as.integer(merged[[var]])
    } else if (type == "character") {
      merged[[var]] <- as.character(merged[[var]])
    }
    # Add other types as necessary
  }
  return(merged)
}

# Function to convert character variables to factors
convert_char_to_factor <- function(merged) {
  merged <- merged %>%
    mutate(across(where(is.character), as.factor))
  return(merged)
}

# Function to calculate the mode for factor variables
calculate_modes <- function(merged) {
  modes <- sapply(merged, function(x) if(is.factor(x)) {
    mode_value <- names(sort(table(x), decreasing = TRUE)[1])
    mode_count <- max(table(x))
    mode_percentage <- (mode_count / length(x)) * 100
    paste0(mode_value, " (", round(mode_percentage, 2), "%)")
  } else NA)
  return(modes)
}

# Function to calculate date statistics for POSIXct columns
calculate_date_statistics <- function(merged) {
  date_stats <- sapply(merged, function(x) if(inherits(x, "POSIXct")) {
    min_date <- format(min(x, na.rm = TRUE), "%Y-%m-%d")
    max_date <- format(max(x, na.rm = TRUE), "%Y-%m-%d")
    num_unique_dates <- length(unique(x))
    median_date <- format(median(x, na.rm = TRUE), "%Y-%m-%d")
    paste0(min_date, " to ", max_date)
  } else NA)
  return(date_stats)
}

# Function to count the number of levels for factor variables
count_levels <- function(merged) {
  num_levels <- sapply(merged, function(x) if(is.factor(x)) length(levels(x)) else NA)
  return(num_levels)
}

# Function to mask sensitive data, only for existing columns
mask_sensitive_data <- function(merged, sensitive_vars) {
  existing_sensitive_vars <- intersect(names(merged), sensitive_vars)
  if(length(existing_sensitive_vars) > 0) {
    merged <- merged %>%
      mutate(across(all_of(existing_sensitive_vars), ~ "Masked"))
  }
  return(merged)
}

# Apply the cleaning function to the dataset
merged_clean <- clean_variable_names(merged)

# Convert character variables to factors
#merged_clean <- convert_char_to_factor(merged_clean)

# Determine variable types using dlookr
variable_types <- diagnose(merged_clean) %>%
  select(variables, types)

# Set variable types based on dlookr diagnostics
merged_clean <- set_variable_types(merged_clean, variable_types)

# Mask sensitive data
merged_clean <- mask_sensitive_data(merged_clean, sensitive_vars)

# Create a mapping table of original and cleaned names, excluding sensitive variables
mapping_table <- tibble(
  original_name = names(merged),
  cleaned_name = names(merged_clean)
) %>%
  filter(!cleaned_name %in% sensitive_vars)

# Calculate means and standard deviations for numeric columns
means_sds <- calculate_means_sds(merged_clean)

# Calculate modes for factor columns
modes <- calculate_modes(merged_clean)

# Calculate date statistics for POSIXct columns
date_statistics <- calculate_date_statistics(merged_clean)

# Count the number of levels for factor variables
num_levels <- count_levels(merged_clean)

# Combine means, modes, date statistics, and sensitive summaries into separate columns
mapping_table <- mapping_table %>%
  mutate(mean_sd = means_sds[!names(means_sds) %in% sensitive_vars],
         mode = modes[!names(modes) %in% sensitive_vars],
         date_range = date_statistics[!names(date_statistics) %in% sensitive_vars],
         num_levels = num_levels[!names(num_levels) %in% sensitive_vars]) %>%
  left_join(variable_types, by = c("cleaned_name" = "variables"))

# Ensure all numeric values in the table are rounded to two decimal places
mapping_table <- mapping_table %>%
  mutate(across(where(is.numeric), ~ round(., 2)))

# Reorder the columns so that summary_statistic is before original_name
mapping_table <- mapping_table %>%
  select(cleaned_name, mean_sd, mode, date_range, num_levels, original_name, types)
```

:::
:::

## Sample Descriptives

::: panel-tabset

### General Data View {.tabset .tabset-fade .tabset-pills}

::: blue

> **This table shows some general info for full sample (including duplicates), will probably be removed later**

```{r}
#| echo: true
#| warning: false

# Render the table using DT::datatable with tooltips and better formatting
datatable(mapping_table, 
          rownames = FALSE,
          caption = 'Summary Statistics Table',
          extensions = 'Buttons',
          options = list(
            pageLength = 10,
            scrollX = TRUE,
            scrollY = "500px",
            dom = 'Bfrtip',
            buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
          )) %>%
  formatStyle(
    columns = names(mapping_table),
    valueColumns = "types",
    backgroundColor = styleEqual(c("numeric", "factor", "POSIXct"), c("lightblue", "lightgreen", "lightpink"))
  )

```
:::

### Community/Residential

::: blue
> **This code creates a basic descriptives table by setting (community vs residential)**

```{r}
#| echo: true
#| warning: false

# Obtain the variable names from the merged dataframe
variables <- names(merged_clean)

# Filter variables that include the sequence "yls"
filtered_variables <- grep("yls", variables, value = TRUE)

# Print the filtered variables
#print(filtered_variables)

# Create a test dataframe with the specified variables
test_df <- merged_clean %>%
  select(
    "age_at_service_start",
    "gender",
    "race",
    "ethnicity",
    "racnicity",
    "age_at_first_referral_date",
    #youth_num_in_cohort,
    #number_of_youth_scoring_low_on_the_yls,
    #number_of_youth_scoring_moderate_on_the_yls,
    #number_of_youth_scoring_high_on_the_yls,
    #number_of_youth_scoring_very_high_on_the_yls,
    #points_received_risk_level_of_youth_youth_scoring_above_low_on_the_yls,
    #points_received_risk_level_of_youth_youth_scoring_above_moderate_on_the_yls,
    setting
  )

# Create a summary table for the full sample
full_sample_summary <- tbl_summary(
  test_df,
  by = setting,
  statistic = list(
    all_continuous() ~ "{mean} ({sd})",
    all_categorical() ~ "{n} ({p}%)"
  ),
  missing = "no"
) %>%
  add_p() %>%
  bold_labels() %>%
  modify_header(label ~ "**Variable**") %>%
  modify_caption("**Descriptive Statistics by Setting**") %>%
  modify_footnote(
    all_stat_cols() ~ "Mean (SD) for continuous variables, N (%) for categorical variables"
  )

# Display the summary table
full_sample_summary

```

:::

### Service Type

::: blue
> **This code creates a basic descriptives table for Service Type (full sample)**

```{r}
#| echo: true
#| warning: false

# Create a test dataframe with the specified variables
test_df <- merged_clean %>%
  select(
    service_type
  )

# Create a summary table for 'service_type'
service_type_summary <- tbl_summary(
  test_df,
  statistic = list(
    all_categorical() ~ "{n} ({p}%)"
  ),
  missing = "no"
) %>%
  bold_labels() %>%
  modify_header(label ~ "**Service Type**") %>%
  modify_caption("**Distribution of Service Type**") %>%
  modify_footnote(
    all_stat_cols() ~ "N (%) for categorical variables"
  )

# Display the summary table
service_type_summary

```

> **This code creates a basic descriptives table for Service Type (no duplicates)**

```{r}
#| echo: true
#| warning: false

# Convert SERVICE_START_DATE to Date type if it's not already
merged$SERVICE_START_DATE <- as.Date(merged$SERVICE_START_DATE, format = "%Y-%m-%d")

# Filter to keep the row with the earliest SERVICE_START_DATE for each UNIQUE_ID
filtered_df <- merged %>%
  group_by(UNIQUE_ID) %>%
  filter(SERVICE_START_DATE == min(SERVICE_START_DATE, na.rm = TRUE)) %>%
  ungroup()

# Create a test dataframe with the specified variable
test_df <- filtered_df %>%
  select(Service_Type)

# Create a summary table for 'service_type'
service_type_summary <- tbl_summary(
  test_df,
  statistic = list(
    all_categorical() ~ "{n} ({p}%)"
  ),
  missing = "no"
) %>%
  bold_labels() %>%
  modify_header(label ~ "**Service Type**") %>%
  modify_caption("**Distribution of Service Type**") %>%
  modify_footnote(
    all_stat_cols() ~ "N (%) for categorical variables"
  )

# Display the summary table
service_type_summary

```
:::

### Risk Scores {.tabset .tabset-fade .tabset-pills}

::: blue

> **This table shows xxxxxx (full-sample)**

```{r}
#| echo: true
#| warning: false

# # Convert SERVICE_START_DATE to Date type if it's not already
# merged$SERVICE_START_DATE <- as.Date(merged$SERVICE_START_DATE, format = "%Y-%m-%d")
# 
# # Filter to keep the row with the earliest SERVICE_START_DATE for each UNIQUE_ID
# filtered_df <- merged %>%
#   group_by(UNIQUE_ID) %>%
#   filter(SERVICE_START_DATE == min(SERVICE_START_DATE, na.rm = TRUE)) %>%
#   ungroup()

# Convert Total_Risk_Desc to a factor
merged$Total_Risk_Desc <- as.factor(merged$Total_Risk_Desc)

# Create a test dataframe with the specified variables
test_df <- merged %>%
  select(Total_Risk_Desc, TOTALSCORE)

# Create summary table for 'Total_Risk_Desc'
total_risk_desc_summary <- tbl_summary(
  test_df %>% select(Total_Risk_Desc),
  statistic = list(
    all_categorical() ~ "{n} ({p}%)"
  ),
  missing = "no"
) %>%
  bold_labels() %>%
  modify_header(label ~ "**Total Risk Description**") %>%
  modify_caption("**Distribution of Total Risk Description**") %>%
  modify_footnote(
    all_stat_cols() ~ "N (%) for categorical variables"
  )

# Create summary table for 'TOTALSCORE'
totalscore_summary <- tbl_summary(
  test_df %>% select(TOTALSCORE),
  statistic = list(
    all_continuous() ~ "{mean} ({sd})"
  ),
  missing = "no"
) %>%
  bold_labels() %>%
  modify_header(label ~ "**Total Score**") %>%
  modify_caption("**Descriptive Statistics for Total Score**") %>%
  modify_footnote(
    all_stat_cols() ~ "Mean (SD) for continuous variables"
  )

# Convert summary tables to gt tables
total_risk_desc_gt <- as_gt(total_risk_desc_summary)
totalscore_gt <- as_gt(totalscore_summary)

# Display the summary tables side by side using gt
#library(gt)
#gt::gtsave(total_risk_desc_gt, "total_risk_desc_summary.html")
#gt::gtsave(totalscore_gt, "totalscore_summary.html")

total_risk_desc_gt
totalscore_gt


```
:::

### Risk Scores II

::: blue
> **This code creates a basic descriptives table for Service Type (no duplicates)**

```{r}
#| echo: true
#| warning: false

# Convert SERVICE_START_DATE to Date type if it's not already
merged$SERVICE_START_DATE <- as.Date(merged$SERVICE_START_DATE, format = "%Y-%m-%d")

# Filter to keep the row with the earliest SERVICE_START_DATE for each UNIQUE_ID
filtered_df <- merged %>%
  group_by(UNIQUE_ID) %>%
  filter(SERVICE_START_DATE == min(SERVICE_START_DATE, na.rm = TRUE)) %>%
  ungroup()

# Convert Total_Risk_Desc to a factor
filtered_df$Total_Risk_Desc <- as.factor(filtered_df$Total_Risk_Desc)

# Create a test dataframe with the specified variables
test_df <- filtered_df %>%
  select(Total_Risk_Desc, TOTALSCORE)

# Create summary table for 'Total_Risk_Desc'
total_risk_desc_summary <- tbl_summary(
  test_df %>% select(Total_Risk_Desc),
  statistic = list(
    all_categorical() ~ "{n} ({p}%)"
  ),
  missing = "no"
) %>%
  bold_labels() %>%
  modify_header(label ~ "**Total Risk Description**") %>%
  modify_caption("**Distribution of Total Risk Description**") %>%
  modify_footnote(
    all_stat_cols() ~ "N (%) for categorical variables"
  )

# Create summary table for 'TOTALSCORE'
totalscore_summary <- tbl_summary(
  test_df %>% select(TOTALSCORE),
  statistic = list(
    all_continuous() ~ "{mean} ({sd})"
  ),
  missing = "no"
) %>%
  bold_labels() %>%
  modify_header(label ~ "**Total Score**") %>%
  modify_caption("**Descriptive Statistics for Total Score**") %>%
  modify_footnote(
    all_stat_cols() ~ "Mean (SD) for continuous variables"
  )

# Convert summary tables to gt tables
total_risk_desc_gt <- as_gt(total_risk_desc_summary)
totalscore_gt <- as_gt(totalscore_summary)

# Display the summary tables side by side using gt
#library(gt)
#gt::gtsave(total_risk_desc_gt, "total_risk_desc_summary.html")
#gt::gtsave(totalscore_gt, "totalscore_summary.html")

total_risk_desc_gt
totalscore_gt



```

:::
:::

## Cohort YLS Descriptives

```{r}
#| echo: false
#| warning: false
#| output: false

# Extract the first 5 characters to identify the cohort
cohort_identifiers <- substr(merged$YOUTH_NUM_IN_COHORT, 1, 5)
# Convert the cohort identifiers to a factor
cohort_identifiers <- as.factor(cohort_identifiers)
# Determine the number of unique cohorts
num_cohorts <- nlevels(cohort_identifiers)

# Count the number of participants in each cohort
participants_per_cohort <- table(cohort_identifiers)

# Convert the result to a data frame for better readability (optional)
participants_per_cohort_df <- as.data.frame(participants_per_cohort)
colnames(participants_per_cohort_df) <- c("Cohort", "Number_of_Participants")

#########

# Extract the first 5 characters to identify the cohort and create a new variable
merged$Cohort <- substr(merged$YOUTH_NUM_IN_COHORT, 1, 5)

# Convert the new variable to an unordered factor
merged$Cohort <- as.factor(merged$Cohort)

# Verify the new variable
#str(merged$Cohort)

# Convert variables to an unordered factors
merged$Total_Risk_Desc <- as.factor(merged$Total_Risk_Desc)

# Step 1: Create a contingency table
contingency_table_YLS <- table(merged$Cohort, merged$Total_Risk_Desc)
#print(contingency_table_YLS)

# Step 2: Convert the contingency table to a data frame
contingency_df_YLS <- as.data.frame.matrix(contingency_table_YLS)

# Step 3: Add a new column with the total count of individuals in each cohort
contingency_df_YLS$Total <- rowSums(contingency_df_YLS)

# Step 4: Rename the 'Total' column to 'Count'
contingency_df_YLS <- contingency_df_YLS %>%
  rownames_to_column(var = "Cohort") %>%
  rename(Count = Total)

# Step 5: Calculate proportions for each risk category and format them as percentages
contingency_df_YLS <- contingency_df_YLS %>%
  mutate(across(c(High, Low, Moderate, `Very High`), ~ sprintf("%d (%d%%)", ., round(./Count * 100))))

# Step 6: Calculate mean and standard deviation for the totalscore variable for each cohort
mean_sd <- merged %>%
  group_by(Cohort) %>%
  summarize(mean_sd = sprintf("%.2f (%.2f)", mean(TOTALSCORE, na.rm = TRUE), sd(TOTALSCORE, na.rm = TRUE)))

# Step 7: Merge the mean(sd) statistics with the contingency table
contingency_df_YLS <- left_join(contingency_df_YLS, mean_sd, by = "Cohort")

# Step 8: Reorder columns so 'Count' is the second column
contingency_df_YLS <- contingency_df_YLS %>%
  select(Cohort, Count, mean_sd, everything())

# Step 9: Sort the data frame in descending order based on 'Count'
contingency_df_YLS <- contingency_df_YLS %>%
  arrange(desc(Count))

# Step x: Add an index column
contingency_df_YLS <- contingency_df_YLS %>%
  mutate(Index = row_number())

# Step x: Reorder the columns to have the index as the first column
contingency_df_YLS <- contingency_df_YLS %>%
  select(Index, everything())

```

::: panel-tabset

### Cohort YLS Table {.tabset .tabset-fade .tabset-pills}

::: blue

> **This table shows descriptives by cohort for YLS scores**

```{r}
#| echo: true
#| warning: false

# Step 2.3: Create and format the table using kable and kableExtra with enhancements
YLS_table <- contingency_df_YLS %>%
  kable("html", col.names = c("Index", "Cohort", "Count", "Mean(SD)", "High", "Low", "Moderate", "Very High"), caption = "Cohort YLS Table") %>%
  kable_styling(full_width = F, position = "center", bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  row_spec(0, bold = TRUE, color = "white", background = "#4CAF50") %>%  # Header row styling
  row_spec(1:nrow(contingency_df_YLS), background = c("#f2f2f2", "white")) %>%  # Alternating row colors
  column_spec(1, bold = TRUE, color = "blue") %>%  # Highlight the Index column
  column_spec(3, background = "#ffebcc") %>%  # Highlight the Count column
  add_header_above(c("Cohort Information" = 3, "YLS Total" = 1, "YLS Risk Levels" = 4)) %>%  # Multi-level header
  footnote(general = "This table provides xxxxx.")  # Add a footnote

# Display the formatted table
YLS_table

```

:::

### Cohort YLS Stats

::: blue

> **This table shows the correlation between cohort size and YLS scores**

```{r}
#| echo: true
#| warning: false

# Calculate the total count for each cohort
count_df <- merged %>%
  group_by(Cohort) %>%
  summarize(Count = n())

# Calculate the mean totalscore for each cohort
mean_totalscore_df <- merged %>%
  group_by(Cohort) %>%
  summarize(TOTALSCORE = mean(TOTALSCORE, na.rm = TRUE))

# Merge the count and mean totalscore data frames
merged_df <- left_join(count_df, mean_totalscore_df, by = "Cohort")

# Perform a correlation test between Count and Mean_TOTALSCORE
correlation_test <- cor.test(merged_df$Count, merged_df$TOTALSCORE, use = "complete.obs")

# Extract the sample size, correlation coefficient, and p-value
sample_size <- length(na.omit(merged_df$Count))
correlation_coefficient <- correlation_test$estimate
p_value <- correlation_test$p.value

# Print the results
cat("Sample Size:", sample_size, "\n")
cat("Correlation Coefficient:", correlation_coefficient, "\n")
cat("P-value:", p_value, "\n")

```

:::
:::

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

## Cohort Service-Type Descriptives

```{r}
#| echo: false
#| warning: false
#| output: false

# Extract the first 5 characters to identify the cohort
cohort_identifiers <- substr(merged$YOUTH_NUM_IN_COHORT, 1, 5)
# Convert the cohort identifiers to a factor
cohort_identifiers <- as.factor(cohort_identifiers)
# Determine the number of unique cohorts
num_cohorts <- nlevels(cohort_identifiers)

# Count the number of participants in each cohort
participants_per_cohort <- table(cohort_identifiers)

# Convert the result to a data frame for better readability (optional)
participants_per_cohort_df <- as.data.frame(participants_per_cohort)
colnames(participants_per_cohort_df) <- c("Cohort", "Number_of_Participants")

#########

# Extract the first 5 characters to identify the cohort and create a new variable
merged$Cohort <- substr(merged$YOUTH_NUM_IN_COHORT, 1, 5)

# Convert the new variable to an unordered factor
merged$Cohort <- as.factor(merged$Cohort)

# Verify the new variable
#str(merged$Cohort)

# Convert variables to an unordered factors
merged$Service_Type <- as.factor(merged$Service_Type)

# Define a function to clean levels of a factor variable
clean_factor_levels <- function(Service_Type) {
  cleaned_levels <- levels(Service_Type) %>%
    str_replace_all("[^[:alnum:]_]", "_") %>%
    str_replace_all("__+", "_") %>%
    str_trim() %>%
    tolower()
  levels(Service_Type) <- cleaned_levels
  return(Service_Type)
}

# Ensure the 'Service_Type' column in merged data frame is a factor
merged$Service_Type <- as.factor(merged$Service_Type)

# Clean the levels of the 'Service_Type' factor variable
merged$Service_Type <- clean_factor_levels(merged$Service_Type)

# Verify the cleaned levels
print(levels(merged$Service_Type))

# Step 1: Create a contingency table
contingency_table_serviceType <- table(merged$Cohort, merged$Service_Type)
#print(contingency_table_serviceType)

# Step 2: Convert the contingency table to a data frame
contingency_df_serviceType <- as.data.frame.matrix(contingency_table_serviceType)

# Step 3: Add a new column with the total count of individuals in each cohort
contingency_df_serviceType$Total <- rowSums(contingency_df_serviceType)

# Step 4: Rename the 'Total' column to 'Count'
contingency_df_serviceType <- contingency_df_serviceType %>%
  rownames_to_column(var = "Cohort") %>%
  rename(Count = Total)

# Step 5: Calculate proportions for each risk category and format them as percentages
contingency_df_serviceType <- contingency_df_serviceType %>%
  mutate(across(contains(" "), ~ sprintf("%d (%d%%)", ., round(./Count * 100))))

# Add a new column with the sum of the service type columns for each individual
service_type_columns <- colnames(contingency_df_serviceType)[3:ncol(contingency_df_serviceType)]
contingency_df_serviceType <- contingency_df_serviceType %>%
  mutate(Service_Type_Sum = rowSums(across(all_of(service_type_columns), ~ as.numeric(gsub(" .*", "", .)))))

# Step 8: Reorder columns so 'Count' is the second column
contingency_df_serviceType <- contingency_df_serviceType %>%
  select(Cohort, Count, Service_Type_Sum, everything())

# Step 9: Sort the data frame in descending order based on 'Count'
contingency_df_serviceType <- contingency_df_serviceType %>%
  arrange(desc(Count))

# Step x: Add an index column
contingency_df_serviceType <- contingency_df_serviceType %>%
  mutate(Index = row_number())

# Step x: Reorder the columns to have the index as the first column
contingency_df_serviceType <- contingency_df_serviceType %>%
  select(Index, everything())

```


::: panel-tabset

### Cohort Service Type Table {.tabset .tabset-fade .tabset-pills}

::: blue

> **This table shows descriptives by cohort for different service types**

```{r}
#| echo: true
#| warning: false

# Create and format the table using kable and kableExtra with enhancements
formatted_table_serviceType <- contingency_df_serviceType %>%
  kable("html", col.names = c("Index", "Cohort", "Count", "Serv_Type_Sum", "ART_Comm_Based", "ART_Res_Prog", "Behav_Manag", "Chall_Progs", "CBT", "Fam_Couns", "Grp_Couns", "Indiv_Couns", "Job_Train", "Voc_Couns", "Mentoring", "Mix_Couns", "MST", "Rem_Acad_Prog", "Rest_Comm_Serv", "Soc_Skills_Train"), caption = "Cohort Service Type Table") %>%
  kable_styling(full_width = F, position = "center", bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  row_spec(0, bold = TRUE, color = "white", background = "#4CAF50") %>%
  row_spec(1:nrow(contingency_df_serviceType), background = c("#f2f2f2", "white")) %>%
  column_spec(1, bold = TRUE, color = "blue") %>%
  column_spec(3, background = "#ffebcc") %>%
  add_header_above(c("Cohort Information" = 4, "YLS Service Types" = 16)) %>%
  footnote(general = "This table provides xxxxx.") %>%
  kable_styling(latex_options = "scale_down") %>%
  column_spec(1:4, bold = TRUE, border_right = TRUE, width = "1.5cm") %>%
  column_spec(5:20, width = "2cm")

# Display the formatted table
formatted_table_serviceType

```

:::

### Cohort Service Type Stats

::: blue

> **This table shows associations between cohort size and service types**

```{r}
#| echo: true
#| warning: false

## TBD

```

:::
:::


